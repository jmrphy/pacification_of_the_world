Bell Labs had its origin in the research laboratory setup by Alexander Graham Bell in 1880 with money he was awarded by the French government for inventing the telephone. The lab was dedicated to the study of sound processing. The modern institution known as Bell Labs was founded in 1925 in the merging of Western Electric's research department and the engineering department of the American Telephone & Telegraph company (AT&T). Its original main focus was to improve the commercial operation of telephone exchange switches, but with an open-ended agenda for extending the frontiers of human knowledge around information processing in general. They also worked for the US government on commission, such as in Project Nike (1945) to develop anti-aircraft technology and the Apollo Program (1961) which would put the first humans on the moon, but they also did pure scientific research at the forefront of the mathematical sciences. Seven Nobel Prizes in Physics were awarded to Bell Labs Researchers between 1937 and 2009.

The achievements within Bell Labs throughout the twentieth century were extraordinary. Perhaps the largest and most well-funded pursuit of scientific knowledge ever mobilized under one organizational umbrella--driven explicitly by the pursuit of profit and then in cooperation with the interests of state power--had a significant role in almost every technological advancement that marked the twentieth century. In the 1920s, Bell Labs was responsible for the first public demonstration of the fax machine, the first motion picture with sound, the first long-distance transmission of television images. Behind these now well-known consumer technologies, however, were the formal mathematical advancements of which these technologies were only applications. In particular, the mathematical advancements all had to do with the nature of information. Thus, it was also in the 1920s that Bell Labs pioneered the essential concepts of what is now known as "statistical process control," the mathematical foundations of measuring the stability and efficiency of processes (of an assembly line, for instance) and designed the first ever technically unbreakable cipher.

In 1947, Bell Labs researchers John Bardeen, Walter Brattain invented the transistor, arguably the most important advancement in twentieth-century electronics. William Shockley, also of Bell Labs, is the figure most directly responsible for the commercialization of the transistor. His Shockley Semiconductor Laboratory, established in Mountain View, California, was the epicenter of what would later become known as Silicon Valley. Although his commercial efforts largely failed, several of Shockley's employees branched out and started more than 60 new enterprises in the same part of California. These enterprises included such names as Intel and ADM. Interestingly, Shockley was also an outspoken racist who believed in eugenics.

It was in 1948 that the Bell Labs Technical Journal published Claude Shannon's "A Mathematical Theory of Communication", the founding document of what would come to be known as information theory.

Shannon's piece is so crucial because it states more exactly than ever before the essential mathematical structure of communication. As Shannon points out, the essence of communication is simply the process of transmitting information from one point to another point. But the defining problem which communication responds to is the fact that the world is composed of "noise," a variable but always-present background of criss-crossing signals through which purposeful communication has to pass. Go into a silent room and notice that if you listen closely you can always hear a soft hum coming from the world, if only the tiniest vibrations of air in your ear. That's noise, but it's relativley little noise, that's why it's easy to communicate with someone in such a silent room. If you're at a music concert and a band is playing, the noise might be so loud that you cannot communicate to anyone at all: this would mean there is so much noise that the signals you're sending never make it into the other person's ear. The reason your friend can't understand you is because your signal is scrambled by the large quantity of other signals in the background.

The formal terms for this essential structure are as follows. An information source produces a message. A transmitter operates on the message to generate a signal. A signal is sent through a channel (with some variable amount of noise). A receiver receives the message and transforms the signal back into a message. Finally, the message arrives at a destination.

![Reproduced from Shannon, Claude. 1948. "A Mathematical Theory of Information." *Bell System Technical Journal* 27 (3): 379â€“423. Image from http://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication.](https://dl.dropboxusercontent.com/u/20498362/Images/Shannon_communication_system.png)

This simple model served as the basis for an extremely sophisticated mathematical development of the nature of communication. The mathematical developments supercharged the rigor and efficiency of a wide variety of real-world endeavours, unsurprisingly centered around maximizing the profits, power, and control of those who put these advancements into practice (indeed "control theory" becomes the literal name of one branch of information theory).

Following Tukey, who used the word in a 1947 Bell Labs internal memo, Shannon deployed the concept of "bit" as the basic unit of information. A bit is simply the amount of information gained when the value of a binary random value (taking the value of either 0 or 1) becomes known. So if there is a 50% chance a coin will land heads rather than tails, and after a flip it indeed lands heads, one bit of information is gleaned.

Shannon is commonly considered the father of the digital revolution because his formalization of the bit as the basic unit of information allowed for more efficient communication, quicker and less noisy than analog.

I think that digitalism is one of the key causal conditions which made possible such a rapid global concentration of economic and political power as the one which began in the 1970s. This marked increase in computational efficiency multiplied the social power of the already dominant institutions, in particular the state and the corporation. And I believe it has led elite social control to a level of stability never before seen in the history of humanity. I think this is one of the most crucial over-arching transformations which characterize the history of most countries in the world from 1970 to today. Needless to say, this remains purely at the level of conjecture and hypothesis. But I think we should see if these theses could be demonstrated.
